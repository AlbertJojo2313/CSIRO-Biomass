{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ba30507b",
   "metadata": {},
   "source": [
    "# Model Training Plan\n",
    "The current strategy is to utilize ensemble idea, one model to identify and output the image \"embeddings\" instead of adding classification. I am outputing the embeddings of the images instead of the classification of the images because:\n",
    "    \n",
    "    - If the classification of the species of grass is wrong then it would propagate to the regression model.\n",
    "\n",
    "    - Usings **\"embeddings\"** avoids information embeddings, a single predited number would throw away the rich visual details.\n",
    "### External Pretraining\n",
    "To pretrain the model to understand grass, weeds, and other plants, before seeing the competition data.\n",
    "\n",
    "1. Choose an image model probably CNN\n",
    "2. Dataset would be either DeepWeeds or GrassClover\n",
    "3. Task:\n",
    "    - Method: Self-supervised\n",
    "    - Action: Train the model to classify the species\n",
    "    - Outcome: The model would ideally ignore light, shadings, and just focus on leaf, shape, stem, and other factors.\n",
    "    - Output: Save these models weights.\n",
    "\n",
    "### Fintune the model on CSIRO\n",
    "Basically, finetune the model to predict the Biomass specifically for the CSIRO dataset.\n",
    "\n",
    "1. Load the output weights.\n",
    "2. Modify Head: Is to replace the final classification layer with a Regression Head (some sort of linearization function)\n",
    "3. Input: **train/** images\n",
    "4. Label: **biomass**\n",
    "5. Loss fn: RMSE or Huber Loss(outliers)\n",
    "6. Training Method:\n",
    "    - Freeze early layers for the first 5 epochs\n",
    "    - Unfreeze all layers and train with a very low learning rate (1 e-4)\n",
    "    - Plan to utilize heavy data augmentation.\n",
    "### Output\n",
    "1. Remove the final regression head\n",
    "2. Ouput: vector (128 or 512) embeddings.\n",
    "3. Process: Pass every image in train/ and test/ folder through the model network.\n",
    "4. Save: A new dataframe where every **sample_id**\n",
    "\n",
    "### Final Model\n",
    "1. Merge Data: Join the embeddings columns with the train.csv on sample id.\n",
    "2. Model would be either an XGboost or CatBoost\n",
    "3. Validate: GroupKFold validation on **Sample Data**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be9b27ba",
   "metadata": {},
   "source": [
    "#### Pre-process"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
